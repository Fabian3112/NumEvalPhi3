{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Datasets\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "import transformers\n",
    "from trl import SFTTrainer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from trl import DataCollatorForCompletionOnlyLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = 'train_output/phi3_qp.txt'\n",
    "out_predictions_file = 'train_output/phi3_qp_predictions.txt'\n",
    "\n",
    "with open(out_file,'a') as f:\n",
    "    f.write('\\n \\n new training: \\n')\n",
    "    f.write('-----------------------------\\n')\n",
    "\n",
    "with open(out_predictions_file,'a') as f:\n",
    "    f.write('\\n \\n new training: \\n')\n",
    "    f.write('-----------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "\n",
    "###################\n",
    "# Hyper-parameters\n",
    "###################\n",
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 5.0e-06,\n",
    "    \"log_level\": \"info\",\n",
    "    #\"logging_steps\": 20,\n",
    "    #\"logging_strategy\": \"epoch\", #\"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": num_epochs,\n",
    "    \"max_steps\": -1,\n",
    "    \"output_dir\": \"./checkpoint_dir_qp\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"remove_unused_columns\": True,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 1,\n",
    "    \"seed\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    }\n",
    "\n",
    "peft_config = {\n",
    "    \"r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"bias\": \"none\",\n",
    "    \"task_type\": \"CAUSAL_LM\",\n",
    "    \"target_modules\": \"all-linear\",\n",
    "    \"modules_to_save\": None,\n",
    "}\n",
    "train_conf = TrainingArguments(**training_config)\n",
    "peft_conf = LoraConfig(**peft_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'models/phi3_4k' #\"microsoft/Phi-3-mini-4k-instruct\"\n",
    "model_kwargs = dict(\n",
    "    use_cache=False,\n",
    "    trust_remote_code=True,\n",
    "    #attn_implementation=\"flash_attention_2\",  # loading the model with flash-attenstion support\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path)#, **model_kwargs) #Uncomment for download\n",
    "checkpoint_path = \"tokenizer/phi3_4k\" #\"microsoft/Phi-3-mini-4k-instruct\" #\"tokenizer/phi3/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "tokenizer.model_max_length = 512#2048\n",
    "tokenizer.pad_token = tokenizer.unk_token  # use unk rather than eos token to prevent endless generation\n",
    "tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "tokenizer.padding_side = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained(\"models/phi3_4k\")\n",
    "#tokenizer.save_pretrained(\"tokenizer/phi3_4k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Datasets.gerernate_qqp('data/QP/Numeracy600K_comment_train.json',tokenizer)\n",
    "dev_dataset = Datasets.gerernate_qqp('data/QP/Numeracy600K_comment_dev.json',tokenizer)\n",
    "test_dataset = Datasets.gerernate_qqp('data/QP/Numeracy600K_comment_test.json',tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset[\"comment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def eval(epoch,train_data,test_data):\n",
    "#\n",
    "#    for mode in [\"train\",\"dev\"]:\n",
    "#        true_count = 0\n",
    "#        total_count = 0\n",
    "#\n",
    "#        if mode == \"train\":\n",
    "#            inputs = train_data\n",
    "#        else:\n",
    "#            inputs = test_data\n",
    "#\n",
    "#\n",
    "#        for i,input in enumerate(inputs[\"inputs\"][:100]):\n",
    "#            total_count += 1\n",
    "#            answer = inputs[\"labels\"][i]\n",
    "#            input = tokenizer.encode(input,return_tensors=\"pt\")\n",
    "#            input = input.to('mps')\n",
    "#            outputs = model.generate(input, max_new_tokens=32)\n",
    "#            text = tokenizer.batch_decode(outputs)[0]\n",
    "#            if answer in text.split(\"<|assistant|>\")[-1]:\n",
    "#                true_count += 1\n",
    "#            #else:\n",
    "#            #    print(f\"worng predicted {text.split(\"<|assistant|>\")[-1]} but was {answer}\")\n",
    "#\n",
    "#        print(mode)    \n",
    "#        print(f'{total_count / len(inputs[\"inputs\"][:100]) *100}% : {true_count/total_count *100}%')\n",
    "#\n",
    "#        with open('train_output/phi3_qp.txt','a') as f:\n",
    "#            f.write(f'{epoch} : {mode} \\n')\n",
    "#            f.write(f'{true_count/total_count *100} % \\n')\n",
    "#\n",
    "#    with open('train_output/phi3_qp.txt','a') as f:\n",
    "#        f.write('-----------------------------')\n",
    "#    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset['inputs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('mps')\n",
    "Datasets.eval(model,tokenizer,0,train_dataset,'train',out_file,out_predictions_file)\n",
    "Datasets.eval(model,tokenizer,0,dev_dataset,'dev',out_file,out_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_template = \"<|user|>\"\n",
    "response_template = \"<|assistant|>\"\n",
    "collator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=train_conf,\n",
    "        train_dataset=train_dataset,  #processed_train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        #max_seq_length=2048,\n",
    "        #dataset_text_field=\"text\",\n",
    "        tokenizer=tokenizer,\n",
    "        #packing=True\n",
    "        data_collator=collator,\n",
    "        peft_config=peft_conf\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    \n",
    "    train_result = trainer.train()\n",
    "\n",
    "    metrics = train_result.metrics\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_state()\n",
    "\n",
    "\n",
    "    with open(out_file,'a') as f:\n",
    "        f.write(f'\\n train metrics {i}: \\n')\n",
    "        f.write(str(metrics))    \n",
    "\n",
    "    \n",
    "    #############\n",
    "    # Evaluation\n",
    "    #############\n",
    "    #tokenizer.padding_side = 'left'\n",
    "    metrics = trainer.evaluate()\n",
    "    metrics[\"eval_samples\"] = len(dev_dataset)\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "\n",
    "    with open(out_file,'a') as f:\n",
    "        f.write(f'\\n dev metrics {i}: \\n')\n",
    "        f.write(str(metrics))    \n",
    "\n",
    "    \n",
    "    Datasets.eval(model,tokenizer,0,train_dataset,'train',out_file,out_predictions_file)\n",
    "    Datasets.eval(model,tokenizer,0,dev_dataset,'dev',out_file,out_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datasets.eval(model,tokenizer,0,test_dataset,'test',out_file,out_predictions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('models/qp/phi3/')\n",
    "tokenizer.save_pretrained('tokenizer/qqa/phi3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
